{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mr-Hari-vignesh/data-science-deja_vu/blob/main/Building_chatbot_willy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jIK1bZB6Hc0",
        "outputId": "ec2934e0-afc9-499e-d68b-fbf2858797af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import string \n",
        "import random\n",
        "import nltk\n",
        "nltk.download('popular')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yASq0j8kEKZW"
      },
      "source": [
        "# Removing Runtime(warnings) from output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P9jhmHTVAp3Z"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw0g7u6G2zXY",
        "outputId": "ca50460e-52f9-4642-c870-d58c3a316b18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "f = open(\"/content/for_testing_chatbot.txt\",\"r\", errors = \"ignore\")\n",
        "raw_doc=f.read()\n",
        "raw_doc=raw_doc.lower() #converts text to lowercase\n",
        "nltk.download(\"punkt\") #using the punkit tokenizer\n",
        "nltk.download(\"wordnet\") #using the wordnet library\n",
        "sent_tokens = nltk.sent_tokenize(raw_doc) #convert doc to list of sentence \n",
        "word_tokens = nltk.word_tokenize(raw_doc) #concert doc to list of wc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LatnmNFAGcZU"
      },
      "source": [
        "# Example of sent tokens "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HgI79JjtyE4",
        "outputId": "93cbdd32-3519-44c5-8a46-3a4f49b8560c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' diggibyte and cuelebre is end to end technology services provider for your data anlaytics needs right from building strategy to architecting the platform and\\n to the deployment of dashboards in cloud/on-prem and we work with modern tools and technologies that modernize,\\n automate & support in solving data challenges with ai & ml by finding the right trends & patterns and we excel in leveraging the most advanced technologies,\\n to accelerate your day-to-day operations and increase business process efficiency by playing around your data to derive valuable outcomes\\n diggibyte solve your business problems by integrating your data engineering and advanced analytics tools & technologies \\n to visit home page : https://diggibyte.com/index.html).', '(address of the diggibyte technologies private limited: (connect with us to achieve new milestones and win your customers)\\n address        : diggibyte technologies private limited,novel tech park,3rd floo,kudlu gate,muneshwara nagar bengaluru,karnataka-560068\\n google location: https://www.google.com/maps/place/novel+tech+park/@12.8914639,77.6414856,17z/data=!3m1!4b1!4m5!3m4!1s0x3bae14b0129745ff:0xf9d4a7aab0502205!8m2!3d12.8914639!4d77.6414856 visit \\n website        : info@diggibyte.com)\\n contact of our sales team  at [sales:sales@diggibyte.com  mobile number: +91-8110889199] \\n contact our human resourse at [hr   :hr@diggibyte.com     mobile number: +91-8110889599].', \"(our valuable partner of diggibyte technologies is [ databricks ] \\n about databricks : our partnership with databricks allows us to leverage scaled computation and advanced machine learning capabilities among databricks' out-of-the-box capacities,\\n databricks is a pioneer and leader in the field,\\n in addition, we have data engineers and data analysts certified in databricks,these experts offer consulting services to help organizations implement real-time solutions and deliver actual value from data,\\n databricks has seamless integration with leading cloud providers such as azure aws and google cloud platform, facilitating processing data needed for advanced ml implementations,\\n diggibyte also has pluggable and customizable assets that integrate with databricks and speed up data onboarding,\\n in addition, diggibyte's team of certified professionals are skilled and proficient in databricks implantation and architectural solution design we set up, develop,\\n and maintain the data pipeline and data analytics solutions on the databricks platform, our databricks partnership allows us to gain exclusive access to new features,\\n training, and resources that directly enable us to solve data challenges for our customers in the most efficient way link: https://diggibyte.com/partners.html#.)\", \"(careers at diggibyte we're more than just a workplace, we're a family,\\n we know that finding a meaningful and rewarding job can be a long journey, our goal is to make that process as easy as possible for you,\\n and to create a work environment that's satisfying - one where you'll look forward to coming to every day,\\n start your journey with us by browsing available jobs link: https://diggibyte.zohorecruit.in/jobs/careers-diggibyte ).\", '(service that provide by diggibyte is:\\n 1) advisory and consulting         : to know more click here : https://diggibyte.com/advisory-consulting.html\\n 2) data and platform engineering   : to know more click here : https://diggibyte.com/data-platform-engg.html\\n 3) data science ai/ml              : to know more click here : https://diggibyte.com/data-science.html\\n 4) advanced and business analytics : to know more click here : https://diggibyte.com/advanced-business-analytics.html\\n 5) devops and maintanance          : to know more click here : https://diggibyte.com/advanced-business-analytics.html ).', \"(resource of our diggibyte technologies are:\\n blog's            : visit : https://blogs.diggibyte.com/\\n whitepaper/e-book : visit : https://blogs.diggibyte.com/whitepaper-e-books/ ).\", '(we combine the latest tools and technologies to accelerate your business growth and increase productivity and efficiency:\\n tools are : \\n1)apache airflow\\n2)amazon athena\\n3)azure iot hub \\n4)beam\\n5)azure devops\\n6)jenkins\\n7)kafka\\n8)knime\\n9)kubernets\\n10)maven\\n11)mongo db\\n12)nosql-net\\n13)amazon redshift\\n14)apache spark\\n15)tensorfow\\n16)docker\\n17)sql  \\nthese are the tools we using in our organization).', '--------------------------------------------------------------------------------------------------------------------------------\\n\\n(data science is an interdisciplinary field that uses scientific methods, processes,\\n algorithms and systems to extract or extrapolate knowledge and insights from noisy, structured and unstructured data,\\n and apply knowledge from data across a broad range of application domains\\n[statistics,\\n visualization,\\n deep learning,\\n machine learning are important data science concepts]\\n to know more visit here: https://en.wikipedia.org/wiki/data_science ).', '(data engineers build systems for collecting, validating, and preparing that high-quality data,\\n data engineers gather and prepare the data and data scientists use the data to promote better business decisions\\n in order to perform their responsibilities efficiently and effectively, data engineers must possess the following technical and soft skills:\\n1)coding\\n2)data warehousing\\n3)knowledge of operating systems\\n4)database systems\\n5)data analysis\\n6)critical thinking skills\\n7)basic understanding of machine learning\\n8)communication skills\\nto know more visit here : https://en.wikipedia.org/wiki/data_engineering ).', '(powerbi is a collection of software services, apps, and connectors that work together to turn your unrelated sources of data into coherent,\\n visually immersive, and interactive insights, your data may be an excel spreadsheet,\\n or a collection of cloud-based and on-premises hybrid data warehouses,\\n one of the most important skills that a power bi developer must have is proficiency or familiarity with data science, business intelligence, and data analytics,\\n power bi developer must also be aware of :\\n1) data integration\\n2) data warehousing, \\n3) modeling along with presentation tactics and concepts\\nto know more visit here : https://en.wikipedia.org/wiki/microsoft_power_bi ).', '(a full stack web developer is a person who can develop both client and server software\\n in addition to mastering html and css, he/she also knows how to: program a browser (like using javascript, jquery, angular, or vue) \\n program a server (like using php, asp, python, or node)\\n to know more visit here : https://en.wikipedia.org/wiki/full_stack ).', '(a devops engineer is an it generalist who should have a wide-ranging knowledge of both development and operations,\\n including coding, infrastructure management, system administration, and devops toolchains,\\n devops engineers should also possess interpersonal skills since they work across company silos to create a more collaborative environment\\nto know more visit here : https://en.wikipedia.org/wiki/devops ).']\n"
          ]
        }
      ],
      "source": [
        "print(sent_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1c1hyqVGszv",
        "outputId": "cd353145-9cc6-4b58-907b-1a376b571573"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' diggibyte and cuelebre is end to end technology services provider for your data anlaytics needs right from building strategy to architecting the platform and\\n to the deployment of dashboards in cloud/on-prem and we work with modern tools and technologies that modernize,\\n automate & support in solving data challenges with ai & ml by finding the right trends & patterns and we excel in leveraging the most advanced technologies,\\n to accelerate your day-to-day operations and increase business process efficiency by playing around your data to derive valuable outcomes\\n diggibyte solve your business problems by integrating your data engineering and advanced analytics tools & technologies \\n to visit home page : https://diggibyte.com/index.html).',\n",
              " '(address of the diggibyte technologies private limited: (connect with us to achieve new milestones and win your customers)\\n address        : diggibyte technologies private limited,novel tech park,3rd floo,kudlu gate,muneshwara nagar bengaluru,karnataka-560068\\n google location: https://www.google.com/maps/place/novel+tech+park/@12.8914639,77.6414856,17z/data=!3m1!4b1!4m5!3m4!1s0x3bae14b0129745ff:0xf9d4a7aab0502205!8m2!3d12.8914639!4d77.6414856 visit \\n website        : info@diggibyte.com)\\n contact of our sales team  at [sales:sales@diggibyte.com  mobile number: +91-8110889199] \\n contact our human resourse at [hr   :hr@diggibyte.com     mobile number: +91-8110889599].']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "sent_tokens[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjfnAbJjHRKY"
      },
      "source": [
        "# Example of word tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZkfg80IHU8i",
        "outputId": "26a390dc-603f-4f23-8e23-964046be7d6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['diggibyte', 'and']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "word_tokens[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0c2Tb6rvh3o",
        "outputId": "8d2f5983-fb44-4ffc-ef44-9a7de64aec8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['diggibyte', 'and', 'cuelebre', 'is', 'end', 'to', 'end', 'technology', 'services', 'provider', 'for', 'your', 'data', 'anlaytics', 'needs', 'right', 'from', 'building', 'strategy', 'to', 'architecting', 'the', 'platform', 'and', 'to', 'the', 'deployment', 'of', 'dashboards', 'in', 'cloud/on-prem', 'and', 'we', 'work', 'with', 'modern', 'tools', 'and', 'technologies', 'that', 'modernize', ',', 'automate', '&', 'support', 'in', 'solving', 'data', 'challenges', 'with', 'ai', '&', 'ml', 'by', 'finding', 'the', 'right', 'trends', '&', 'patterns', 'and', 'we', 'excel', 'in', 'leveraging', 'the', 'most', 'advanced', 'technologies', ',', 'to', 'accelerate', 'your', 'day-to-day', 'operations', 'and', 'increase', 'business', 'process', 'efficiency', 'by', 'playing', 'around', 'your', 'data', 'to', 'derive', 'valuable', 'outcomes', 'diggibyte', 'solve', 'your', 'business', 'problems', 'by', 'integrating', 'your', 'data', 'engineering', 'and', 'advanced', 'analytics', 'tools', '&', 'technologies', 'to', 'visit', 'home', 'page', ':', 'https', ':', '//diggibyte.com/index.html', ')', '.', '(', 'address', 'of', 'the', 'diggibyte', 'technologies', 'private', 'limited', ':', '(', 'connect', 'with', 'us', 'to', 'achieve', 'new', 'milestones', 'and', 'win', 'your', 'customers', ')', 'address', ':', 'diggibyte', 'technologies', 'private', 'limited', ',', 'novel', 'tech', 'park,3rd', 'floo', ',', 'kudlu', 'gate', ',', 'muneshwara', 'nagar', 'bengaluru', ',', 'karnataka-560068', 'google', 'location', ':', 'https', ':', '//www.google.com/maps/place/novel+tech+park/', '@', '12.8914639,77.6414856,17z/data=', '!', '3m1', '!', '4b1', '!', '4m5', '!', '3m4', '!', '1s0x3bae14b0129745ff:0xf9d4a7aab0502205', '!', '8m2', '!', '3d12.8914639', '!', '4d77.6414856', 'visit', 'website', ':', 'info', '@', 'diggibyte.com', ')', 'contact', 'of', 'our', 'sales', 'team', 'at', '[', 'sales', ':', 'sales', '@', 'diggibyte.com', 'mobile', 'number', ':', '+91-8110889199', ']', 'contact', 'our', 'human', 'resourse', 'at', '[', 'hr', ':', 'hr', '@', 'diggibyte.com', 'mobile', 'number', ':', '+91-8110889599', ']', '.', '(', 'our', 'valuable', 'partner', 'of', 'diggibyte', 'technologies', 'is', '[', 'databricks', ']', 'about', 'databricks', ':', 'our', 'partnership', 'with', 'databricks', 'allows', 'us', 'to', 'leverage', 'scaled', 'computation', 'and', 'advanced', 'machine', 'learning', 'capabilities', 'among', 'databricks', \"'\", 'out-of-the-box', 'capacities', ',', 'databricks', 'is', 'a', 'pioneer', 'and', 'leader', 'in', 'the', 'field', ',', 'in', 'addition', ',', 'we', 'have', 'data', 'engineers', 'and', 'data', 'analysts', 'certified', 'in', 'databricks', ',', 'these', 'experts', 'offer', 'consulting', 'services', 'to', 'help', 'organizations', 'implement', 'real-time', 'solutions', 'and', 'deliver', 'actual', 'value', 'from', 'data', ',', 'databricks', 'has', 'seamless', 'integration', 'with', 'leading', 'cloud', 'providers', 'such', 'as', 'azure', 'aws', 'and', 'google', 'cloud', 'platform', ',', 'facilitating', 'processing', 'data', 'needed', 'for', 'advanced', 'ml', 'implementations', ',', 'diggibyte', 'also', 'has', 'pluggable', 'and', 'customizable', 'assets', 'that', 'integrate', 'with', 'databricks', 'and', 'speed', 'up', 'data', 'onboarding', ',', 'in', 'addition', ',', 'diggibyte', \"'s\", 'team', 'of', 'certified', 'professionals', 'are', 'skilled', 'and', 'proficient', 'in', 'databricks', 'implantation', 'and', 'architectural', 'solution', 'design', 'we', 'set', 'up', ',', 'develop', ',', 'and', 'maintain', 'the', 'data', 'pipeline', 'and', 'data', 'analytics', 'solutions', 'on', 'the', 'databricks', 'platform', ',', 'our', 'databricks', 'partnership', 'allows', 'us', 'to', 'gain', 'exclusive', 'access', 'to', 'new', 'features', ',', 'training', ',', 'and', 'resources', 'that', 'directly', 'enable', 'us', 'to', 'solve', 'data', 'challenges', 'for', 'our', 'customers', 'in', 'the', 'most', 'efficient', 'way', 'link', ':', 'https', ':', '//diggibyte.com/partners.html', '#', '.', ')', '(', 'careers', 'at', 'diggibyte', 'we', \"'re\", 'more', 'than', 'just', 'a', 'workplace', ',', 'we', \"'re\", 'a', 'family', ',', 'we', 'know', 'that', 'finding', 'a', 'meaningful', 'and', 'rewarding', 'job', 'can', 'be', 'a', 'long', 'journey', ',', 'our', 'goal', 'is', 'to', 'make', 'that', 'process', 'as', 'easy', 'as', 'possible', 'for', 'you', ',', 'and', 'to', 'create', 'a', 'work', 'environment', 'that', \"'s\", 'satisfying', '-', 'one', 'where', 'you', \"'ll\", 'look', 'forward', 'to', 'coming', 'to', 'every', 'day', ',', 'start', 'your', 'journey', 'with', 'us', 'by', 'browsing', 'available', 'jobs', 'link', ':', 'https', ':', '//diggibyte.zohorecruit.in/jobs/careers-diggibyte', ')', '.', '(', 'service', 'that', 'provide', 'by', 'diggibyte', 'is', ':', '1', ')', 'advisory', 'and', 'consulting', ':', 'to', 'know', 'more', 'click', 'here', ':', 'https', ':', '//diggibyte.com/advisory-consulting.html', '2', ')', 'data', 'and', 'platform', 'engineering', ':', 'to', 'know', 'more', 'click', 'here', ':', 'https', ':', '//diggibyte.com/data-platform-engg.html', '3', ')', 'data', 'science', 'ai/ml', ':', 'to', 'know', 'more', 'click', 'here', ':', 'https', ':', '//diggibyte.com/data-science.html', '4', ')', 'advanced', 'and', 'business', 'analytics', ':', 'to', 'know', 'more', 'click', 'here', ':', 'https', ':', '//diggibyte.com/advanced-business-analytics.html', '5', ')', 'devops', 'and', 'maintanance', ':', 'to', 'know', 'more', 'click', 'here', ':', 'https', ':', '//diggibyte.com/advanced-business-analytics.html', ')', '.', '(', 'resource', 'of', 'our', 'diggibyte', 'technologies', 'are', ':', 'blog', \"'s\", ':', 'visit', ':', 'https', ':', '//blogs.diggibyte.com/', 'whitepaper/e-book', ':', 'visit', ':', 'https', ':', '//blogs.diggibyte.com/whitepaper-e-books/', ')', '.', '(', 'we', 'combine', 'the', 'latest', 'tools', 'and', 'technologies', 'to', 'accelerate', 'your', 'business', 'growth', 'and', 'increase', 'productivity', 'and', 'efficiency', ':', 'tools', 'are', ':', '1', ')', 'apache', 'airflow', '2', ')', 'amazon', 'athena', '3', ')', 'azure', 'iot', 'hub', '4', ')', 'beam', '5', ')', 'azure', 'devops', '6', ')', 'jenkins', '7', ')', 'kafka', '8', ')', 'knime', '9', ')', 'kubernets', '10', ')', 'maven', '11', ')', 'mongo', 'db', '12', ')', 'nosql-net', '13', ')', 'amazon', 'redshift', '14', ')', 'apache', 'spark', '15', ')', 'tensorfow', '16', ')', 'docker', '17', ')', 'sql', 'these', 'are', 'the', 'tools', 'we', 'using', 'in', 'our', 'organization', ')', '.', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '(', 'data', 'science', 'is', 'an', 'interdisciplinary', 'field', 'that', 'uses', 'scientific', 'methods', ',', 'processes', ',', 'algorithms', 'and', 'systems', 'to', 'extract', 'or', 'extrapolate', 'knowledge', 'and', 'insights', 'from', 'noisy', ',', 'structured', 'and', 'unstructured', 'data', ',', 'and', 'apply', 'knowledge', 'from', 'data', 'across', 'a', 'broad', 'range', 'of', 'application', 'domains', '[', 'statistics', ',', 'visualization', ',', 'deep', 'learning', ',', 'machine', 'learning', 'are', 'important', 'data', 'science', 'concepts', ']', 'to', 'know', 'more', 'visit', 'here', ':', 'https', ':', '//en.wikipedia.org/wiki/data_science', ')', '.', '(', 'data', 'engineers', 'build', 'systems', 'for', 'collecting', ',', 'validating', ',', 'and', 'preparing', 'that', 'high-quality', 'data', ',', 'data', 'engineers', 'gather', 'and', 'prepare', 'the', 'data', 'and', 'data', 'scientists', 'use', 'the', 'data', 'to', 'promote', 'better', 'business', 'decisions', 'in', 'order', 'to', 'perform', 'their', 'responsibilities', 'efficiently', 'and', 'effectively', ',', 'data', 'engineers', 'must', 'possess', 'the', 'following', 'technical', 'and', 'soft', 'skills', ':', '1', ')', 'coding', '2', ')', 'data', 'warehousing', '3', ')', 'knowledge', 'of', 'operating', 'systems', '4', ')', 'database', 'systems', '5', ')', 'data', 'analysis', '6', ')', 'critical', 'thinking', 'skills', '7', ')', 'basic', 'understanding', 'of', 'machine', 'learning', '8', ')', 'communication', 'skills', 'to', 'know', 'more', 'visit', 'here', ':', 'https', ':', '//en.wikipedia.org/wiki/data_engineering', ')', '.', '(', 'powerbi', 'is', 'a', 'collection', 'of', 'software', 'services', ',', 'apps', ',', 'and', 'connectors', 'that', 'work', 'together', 'to', 'turn', 'your', 'unrelated', 'sources', 'of', 'data', 'into', 'coherent', ',', 'visually', 'immersive', ',', 'and', 'interactive', 'insights', ',', 'your', 'data', 'may', 'be', 'an', 'excel', 'spreadsheet', ',', 'or', 'a', 'collection', 'of', 'cloud-based', 'and', 'on-premises', 'hybrid', 'data', 'warehouses', ',', 'one', 'of', 'the', 'most', 'important', 'skills', 'that', 'a', 'power', 'bi', 'developer', 'must', 'have', 'is', 'proficiency', 'or', 'familiarity', 'with', 'data', 'science', ',', 'business', 'intelligence', ',', 'and', 'data', 'analytics', ',', 'power', 'bi', 'developer', 'must', 'also', 'be', 'aware', 'of', ':', '1', ')', 'data', 'integration', '2', ')', 'data', 'warehousing', ',', '3', ')', 'modeling', 'along', 'with', 'presentation', 'tactics', 'and', 'concepts', 'to', 'know', 'more', 'visit', 'here', ':', 'https', ':', '//en.wikipedia.org/wiki/microsoft_power_bi', ')', '.', '(', 'a', 'full', 'stack', 'web', 'developer', 'is', 'a', 'person', 'who', 'can', 'develop', 'both', 'client', 'and', 'server', 'software', 'in', 'addition', 'to', 'mastering', 'html', 'and', 'css', ',', 'he/she', 'also', 'knows', 'how', 'to', ':', 'program', 'a', 'browser', '(', 'like', 'using', 'javascript', ',', 'jquery', ',', 'angular', ',', 'or', 'vue', ')', 'program', 'a', 'server', '(', 'like', 'using', 'php', ',', 'asp', ',', 'python', ',', 'or', 'node', ')', 'to', 'know', 'more', 'visit', 'here', ':', 'https', ':', '//en.wikipedia.org/wiki/full_stack', ')', '.', '(', 'a', 'devops', 'engineer', 'is', 'an', 'it', 'generalist', 'who', 'should', 'have', 'a', 'wide-ranging', 'knowledge', 'of', 'both', 'development', 'and', 'operations', ',', 'including', 'coding', ',', 'infrastructure', 'management', ',', 'system', 'administration', ',', 'and', 'devops', 'toolchains', ',', 'devops', 'engineers', 'should', 'also', 'possess', 'interpersonal', 'skills', 'since', 'they', 'work', 'across', 'company', 'silos', 'to', 'create', 'a', 'more', 'collaborative', 'environment', 'to', 'know', 'more', 'visit', 'here', ':', 'https', ':', '//en.wikipedia.org/wiki/devops', ')', '.']\n"
          ]
        }
      ],
      "source": [
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55fl4QmzHd_Z"
      },
      "source": [
        "# Text pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "n2jhPYzLvr27"
      },
      "outputs": [],
      "source": [
        "#wordnet is a semantically-oriented dictonary of english included in NLTK\n",
        "lemonizing = nltk.stem.WordNetLemmatizer()\n",
        "def LemTokens(tokens):\n",
        "  return[lemonizing.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct),None) for punct in string.punctuation)  \n",
        "def LemNormalize(text):\n",
        "  return LemTokens(nltk.wordpunct_tokenize(text.lower().translate(remove_punct_dict)))\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl82do5aK8WR"
      },
      "source": [
        "# Defining the greeting function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YSg7XH08KrM7"
      },
      "outputs": [],
      "source": [
        "Greet_inputs = (\"hello\",\"hi\",\"greetings\",\"sup\",\"whats,up\",\"hey\",\"hie\")\n",
        "Greet_response = (\"hi iam willy\",\"hey friend iam willy\",\"hie there how can i help you\",\"hello iam willy how can i assist you\",\"I am glad! you are talking with me\")\n",
        "def greet(sentance):\n",
        "\n",
        "  for word in sentance.split():\n",
        "    if word.lower() in Greet_inputs:\n",
        "      return random.choice(Greet_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSmWbUE3PKEl"
      },
      "source": [
        "# Response generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "L6Ms_brIPOco"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tTYcb9jFOyA_"
      },
      "outputs": [],
      "source": [
        "def response(user_response):\n",
        "  willy1_response=\"\"\n",
        "  TfidVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=\"english\")\n",
        "  tfidf = TfidVec.fit_transform(sent_tokens)\n",
        "  vals = cosine_similarity(tfidf[-1],tfidf)\n",
        "  idx = vals.argsort()[0][-2]\n",
        "  flat = vals.flatten()\n",
        "  flat.sort()\n",
        "  req_tfidf = flat[-2]\n",
        "  if(req_tfidf==0):\n",
        "    willy1_response = willy1_response+\"I am sorry ! I didnt understand you\"\n",
        "    return willy1_response\n",
        "  else:\n",
        "    willy1_response = willy1_response+sent_tokens[idx]\n",
        "    return willy1_response  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zrj2cmJBPIto"
      },
      "source": [
        "## Defining conversation start/end protocols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yduWOUQyORsD",
        "outputId": "429ac07a-b1f7-46ac-f21c-3232bb296f15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOT: my name is willy.\n",
            "(Iam working for DIGGIBYTE TECHNOLOGIES)\n",
            "How can i assist you, if you like to ( Exit/End-conversation ) any time , just type Bye!\n",
            "hie\n",
            "Willy: I am glad! you are talking with me\n",
            "what is powerbi\n",
            "Willy: (powerbi is a collection of software services, apps, and connectors that work together to turn your unrelated sources of data into coherent,\n",
            " visually immersive, and interactive insights, your data may be an excel spreadsheet,\n",
            " or a collection of cloud-based and on-premises hybrid data warehouses,\n",
            " one of the most important skills that a power bi developer must have is proficiency or familiarity with data science, business intelligence, and data analytics,\n",
            " power bi developer must also be aware of :\n",
            "1) data integration\n",
            "2) data warehousing, \n",
            "3) modeling along with presentation tactics and concepts\n",
            "to know more visit here : https://en.wikipedia.org/wiki/microsoft_power_bi ).\n",
            "what is devops\n",
            "Willy: (a devops engineer is an it generalist who should have a wide-ranging knowledge of both development and operations,\n",
            " including coding, infrastructure management, system administration, and devops toolchains,\n",
            " devops engineers should also possess interpersonal skills since they work across company silos to create a more collaborative environment\n",
            "to know more visit here : https://en.wikipedia.org/wiki/devops ).\n",
            "what is data science\n",
            "Willy: --------------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "(data science is an interdisciplinary field that uses scientific methods, processes,\n",
            " algorithms and systems to extract or extrapolate knowledge and insights from noisy, structured and unstructured data,\n",
            " and apply knowledge from data across a broad range of application domains\n",
            "[statistics,\n",
            " visualization,\n",
            " deep learning,\n",
            " machine learning are important data science concepts]\n",
            " to know more visit here: https://en.wikipedia.org/wiki/data_science ).\n",
            "data engineer\n",
            "Willy: (data engineers build systems for collecting, validating, and preparing that high-quality data,\n",
            " data engineers gather and prepare the data and data scientists use the data to promote better business decisions\n",
            " in order to perform their responsibilities efficiently and effectively, data engineers must possess the following technical and soft skills:\n",
            "1)coding\n",
            "2)data warehousing\n",
            "3)knowledge of operating systems\n",
            "4)database systems\n",
            "5)data analysis\n",
            "6)critical thinking skills\n",
            "7)basic understanding of machine learning\n",
            "8)communication skills\n",
            "to know more visit here : https://en.wikipedia.org/wiki/data_engineering ).\n"
          ]
        }
      ],
      "source": [
        "flag = True\n",
        "print(\"BOT: my name is willy.\\n(Iam working for DIGGIBYTE TECHNOLOGIES)\\nHow can i assist you, if you like to ( Exit/End-conversation ) any time , just type Bye!\")\n",
        "while(flag==True):\n",
        "  user_response = input()\n",
        "  user_response = user_response.lower()\n",
        "  if(user_response!=\"bye\"):\n",
        "    if(user_response==\"thanks\" or user_response==\"thank you\"):\n",
        "      flag=False\n",
        "      print(\"willy: you are welcome..\")\n",
        "    else:\n",
        "      if(greet(user_response)!=None):\n",
        "        print(\"Willy: \"+greet(user_response))\n",
        "      else:\n",
        "        sent_tokens.append(user_response)\n",
        "        word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
        "        final_words=list(set(word_tokens))\n",
        "        print(\"Willy: \",end=\"\")\n",
        "        print(response(user_response))\n",
        "        sent_tokens.remove(user_response)\n",
        "  else:\n",
        "    flag=False\n",
        "    print(\"willy: Goodbye! Take care ( Thanks for visiting Diggibyte technology)\")         "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hALNmlrNGldv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n3hTkLQJCqf0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyOLCNxksseUByUbv/WIWk2d",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}